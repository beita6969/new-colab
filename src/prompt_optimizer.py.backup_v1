#!/usr/bin/env python3
"""
æç¤ºè¯ä¼˜åŒ–å™¨ - Layer 1: Workflowç”Ÿæˆæç¤ºè¯åŠ¨æ€ä¼˜åŒ–
"""
from typing import Dict, List, Optional
from experience_buffer import ExperienceBuffer


class PromptOptimizer:
    """
    åŠ¨æ€æç¤ºè¯ä¼˜åŒ–å™¨

    åŠŸèƒ½ï¼š
    1. æä¾›å®Œæ•´7ä¸ªoperatoræ¨¡æ¿
    2. Few-shotç¤ºä¾‹å­¦ä¹ ï¼ˆä»experience_bufferæ£€ç´¢ï¼‰
    3. é—®é¢˜ç±»å‹è‡ªé€‚åº”æŒ‡å¯¼
    4. åŠ¨æ€ç»„åˆç”Ÿæˆæœ€ä¼˜æç¤ºè¯
    """

    def __init__(self, experience_buffer: Optional[ExperienceBuffer] = None):
        """
        Args:
            experience_buffer: é«˜è´¨é‡æ ·æœ¬ç¼“å†²åŒºï¼ˆç”¨äºfew-shotï¼‰
        """
        self.experience_buffer = experience_buffer
        self.operator_templates = self._load_operator_templates()
        self.type_guidance = self._load_type_guidance()

    def build_dynamic_prompt(
        self,
        problem: str,
        problem_type: str,
        use_few_shot: bool = True,
        few_shot_k: int = 3,
        similarity_threshold: float = 0.7
    ) -> str:
        """
        æ„å»ºåŠ¨æ€ä¼˜åŒ–çš„æç¤ºè¯

        Args:
            problem: é—®é¢˜æ–‡æœ¬
            problem_type: é—®é¢˜ç±»å‹ (math/code/qa)
            use_few_shot: æ˜¯å¦ä½¿ç”¨few-shotç¤ºä¾‹
            few_shot_k: few-shotç¤ºä¾‹æ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            ä¼˜åŒ–åçš„å®Œæ•´æç¤ºè¯
        """
        # 1. åŸºç¡€æ¨¡æ¿ï¼ˆå®Œæ•´7ç®—å­ï¼‰
        base_template = self._get_full_operator_template()

        # 2. Few-shotç¤ºä¾‹ï¼ˆå¯é€‰ï¼‰
        few_shot_section = ""
        if use_few_shot and self.experience_buffer is not None:
            few_shot_examples = self.experience_buffer.retrieve_top_k(
                problem=problem,
                problem_type=problem_type,
                k=few_shot_k,
                similarity_threshold=similarity_threshold
            )

            if len(few_shot_examples) > 0:
                few_shot_section = self._format_few_shot_examples(few_shot_examples)

        # 3. ç±»å‹è‡ªé€‚åº”æŒ‡å¯¼
        type_guidance_section = self.type_guidance.get(
            problem_type,
            self.type_guidance["qa"]  # é»˜è®¤ä½¿ç”¨QAæŒ‡å¯¼
        )

        # 4. æ ¹æ®é—®é¢˜ç±»å‹ç¡®å®šworkflowç­¾å
        if problem_type == "code":
            call_signature = "async def __call__(self, problem: str, entry_point: str, test: str):"
            call_comment = """# Solve: {problem}
        # entry_point: The function name to test (HumanEval format)
        # test: The test code containing check() function (HumanEval format)
        # MUST return (solution, cost) tuple
        # Example: return code, self.llm.get_usage_summary()["total_cost"]"""
        else:
            call_signature = "async def __call__(self, problem: str):"
            call_comment = """# Solve: {problem}
        # MUST return (solution, cost) tuple
        # Example: return solution['response'], self.llm.get_usage_summary()["total_cost"]"""

        # 5. ç»„åˆæç¤ºè¯
        prompt = f"""Generate a Python Workflow class. Follow the exact template and API signatures.

CRITICAL: Only use operators listed below with their EXACT parameters!

{base_template}

{type_guidance_section}

{few_shot_section}

Template (complete the __call__ method):

import workspace.{problem_type}.workflows.template.operator as operator
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        # Initialize operators you need, e.g.:
        # self.custom = operator.Custom(self.llm)
        # self.answer_generate = operator.AnswerGenerate(self.llm)
        # self.programmer = operator.Programmer(self.llm)
        # self.sc_ensemble = operator.ScEnsemble(self.llm)
        # self.test = operator.Test(self.llm)
        # self.review = operator.Review(self.llm)
        # self.revise = operator.Revise(self.llm)

    {call_signature}
        {call_comment}
        pass
"""

        return prompt

    def _get_full_operator_template(self) -> str:
        """
        è¿”å›å®Œæ•´7ä¸ªoperatorçš„æ¨¡æ¿å®šä¹‰

        Returns:
            å®Œæ•´operatoråˆ—è¡¨è¯´æ˜
        """
        return """Available Operators (7 total - use intelligently based on problem type):

1. Custom(llm) - Most flexible, for any custom task
   Call: await self.custom(input=str, instruction=str)
   Returns: {'response': str}
   Use case: General purpose tasks, flexible prompting

2. AnswerGenerate(llm) - Step-by-step reasoning
   Call: await self.answer_generate(input=str)  â† NO instruction parameter!
   Returns: {'thought': str, 'answer': str}
   Use case: Problems requiring step-by-step reasoning

3. Programmer(llm) - Auto-generate and execute Python code
   Call: await self.programmer(problem=str, analysis=str)
   Returns: {'code': str, 'output': str}
   Use case: Mathematical calculations, code generation

4. ScEnsemble(llm) - Self-consistency ensemble (multiple solutions voting)
   Call: await self.sc_ensemble(solutions=List[str], problem=str)
   Returns: {'response': str}
   Use case: When answer is uncertain, generate multiple solutions and vote
   Recommended: Use after AnswerGenerate for verification

5. Test(llm) - Test generated code with test cases
   Call: await self.test(problem=str, solution=str, entry_point=str, test=str)
   Returns: {'result': bool, 'solution': str}
   Use case: ALWAYS test code solutions before returning
   CRITICAL: Code problems should use this!
   Note: For HumanEval, test parameter contains the check function

6. Review(llm) - Review and verify a solution
   Call: await self.review(problem=str, solution=str)
   Returns: {'review_result': str, 'feedback': str}
   Use case: Complex problems need self-review to catch errors

7. Revise(llm) - Revise solution based on feedback
   Call: await self.revise(problem=str, solution=str, feedback=str)
   Returns: {'solution': str}
   Use case: Fix issues found in review, iterative improvement"""

    def _load_operator_templates(self) -> Dict:
        """
        åŠ è½½operatoræ¨¡æ¿å®šä¹‰

        Returns:
            operatoræ¨¡æ¿å­—å…¸
        """
        return {
            "Custom": {
                "description": "Most flexible, for any custom task",
                "interface": "custom(input: str, instruction: str)",
                "returns": "{'response': str}"
            },
            "AnswerGenerate": {
                "description": "Step-by-step reasoning",
                "interface": "answer_generate(input: str)",
                "returns": "{'thought': str, 'answer': str}"
            },
            "Programmer": {
                "description": "Auto-generate and execute Python code",
                "interface": "programmer(problem: str, analysis: str)",
                "returns": "{'code': str, 'output': str}"
            },
            "ScEnsemble": {
                "description": "Self-consistency ensemble",
                "interface": "sc_ensemble(solutions: List[str], problem: str)",
                "returns": "{'response': str}"
            },
            "Test": {
                "description": "Test the solution with test cases, if correct return 'no error'; if incorrect, reflect on the error",
                "interface": "test(problem: str, solution: str, entry_point: str, test: str = '')",
                "returns": "{'result': bool, 'solution': str}",
                "note": "For HumanEval, test parameter contains the check function"
            },
            "Review": {
                "description": "Review and verify solution",
                "interface": "review(problem: str, solution: str)",
                "returns": "{'review_result': str, 'feedback': str}"
            },
            "Revise": {
                "description": "Revise based on feedback",
                "interface": "revise(problem: str, solution: str, feedback: str)",
                "returns": "{'solution': str}"
            }
        }

    def _load_type_guidance(self) -> Dict:
        """
        åŠ è½½é—®é¢˜ç±»å‹è‡ªé€‚åº”æŒ‡å¯¼

        Returns:
            ç±»å‹æŒ‡å¯¼å­—å…¸
        """
        return {
            "math": """
ğŸ¯ Recommended Workflow for MATH Problems:

Strategy 1 (Simple calculation):
  1. AnswerGenerate â†’ step-by-step reasoning
  2. Return answer directly

Strategy 2 (Complex calculation):
  1. AnswerGenerate â†’ understand the problem
  2. Programmer â†’ write Python code to calculate
  3. Return calculation result

Strategy 3 (High uncertainty):
  1. AnswerGenerate â†’ get initial solution
  2. ScEnsemble â†’ verify with multiple attempts
  3. Return most consistent answer

Best Practice:
- Use AnswerGenerate for algebraic reasoning
- Use Programmer for numerical calculations
- Use ScEnsemble when answer is uncertain
- Always format final answer with \\boxed{} notation
""",
            "code": """
ğŸ¯ Recommended Workflow for CODE Problems:

âš ï¸ CRITICAL - CODE WORKFLOW SIGNATURE:
Your __call__ method MUST accept these parameters:
  async def __call__(self, problem: str, entry_point: str, test: str):

  - problem: The problem description
  - entry_point: Function name to test (e.g., "has_close_elements")
  - test: HumanEval test code containing check() function

Standard Workflow (RECOMMENDED):
  1. Programmer â†’ generate code solution
  2. Test â†’ ALWAYS validate with entry_point and test parameters
     await self.test(problem=problem, solution=code, entry_point=entry_point, test=test)
  3. Review â†’ check code quality (if complex)
  4. Revise â†’ fix bugs if test fails

CRITICAL:
- Code solutions MUST be tested with Test operator!
- MUST use the entry_point and test parameters from __call__!
- Return the generated CODE, not explanatory text
- Ensure code is executable and self-contained
- Handle errors gracefully

Example Test operator call:
  test_result = await self.test(
      problem=problem,
      solution=generated_code,
      entry_point=entry_point,  # Use the parameter!
      test=test                  # Use the parameter!
  )
""",
            "qa": """
ğŸ¯ Recommended Workflow for QA Problems:

Strategy 1 (Simple factual):
  1. AnswerGenerate â†’ get comprehensive answer
  2. Return answer directly

Strategy 2 (Complex/uncertain):
  1. AnswerGenerate â†’ initial answer
  2. Review â†’ verify factual accuracy
  3. Revise â†’ improve clarity if needed

Strategy 3 (Multi-perspective):
  1. Custom â†’ gather multiple perspectives
  2. ScEnsemble â†’ integrate viewpoints
  3. Return integrated answer

Best Practice:
- Keep answers concise and accurate
- Use Review for complex questions
- Verify facts when uncertain
"""
        }

    def _format_few_shot_examples(self, examples: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–few-shotç¤ºä¾‹

        Args:
            examples: æ ·æœ¬åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„few-shotç¤ºä¾‹æ–‡æœ¬
        """
        if len(examples) == 0:
            return ""

        few_shot_text = "=" * 60 + "\n"
        few_shot_text += "ğŸ“š HIGH-QUALITY WORKFLOW EXAMPLES (Learn from these!)\n"
        few_shot_text += "=" * 60 + "\n\n"

        for i, example in enumerate(examples, 1):
            # æå–å…³é”®ä¿¡æ¯
            problem = example.get('problem', '')
            workflow_code = example.get('workflow_code', '')
            reward = example.get('reward', 0)
            correctness = example.get('correctness_score', 0)

            # æˆªæ–­è¿‡é•¿çš„workflowä»£ç 
            if len(workflow_code) > 1000:
                workflow_code = workflow_code[:1000] + "\n    # ... (truncated)"

            few_shot_text += f"Example {i} (Reward: {reward:.1f}, Correctness: {correctness:.1f}/10):\n"
            few_shot_text += f"Problem: {problem}\n\n"
            few_shot_text += f"Successful Workflow:\n```python\n{workflow_code}\n```\n\n"

        few_shot_text += "=" * 60 + "\n"
        few_shot_text += "Now generate a workflow for your problem following similar patterns!\n"
        few_shot_text += "=" * 60 + "\n\n"

        return few_shot_text

    def get_operator_count(self, workflow_code: str) -> Dict[str, int]:
        """
        ç»Ÿè®¡workflowä¸­ä½¿ç”¨çš„operatoræ•°é‡

        Args:
            workflow_code: workflowä»£ç 

        Returns:
            operatorä½¿ç”¨è®¡æ•°å­—å…¸
        """
        operator_count = {name: 0 for name in self.operator_templates.keys()}

        for op_name in self.operator_templates.keys():
            # æ£€æŸ¥åˆå§‹åŒ–å’Œè°ƒç”¨
            if f'operator.{op_name}' in workflow_code or \
               f'self.{op_name.lower()}' in workflow_code:
                operator_count[op_name] += 1

        return operator_count
