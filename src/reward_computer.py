#!/usr/bin/env python3
"""
å¥–åŠ±è®¡ç®—å™¨ - æ”¹è¿›ç‰ˆ(å€Ÿé‰´ROLLå’ŒAgentFlowè®¾è®¡)
"""
import sys
import re
from typing import Any, Dict, Optional

# æ·»åŠ AFlowåˆ°è·¯å¾„
sys.path.insert(0, '/home/yijia/.claude/11/AFlow')

# å¯¼å…¥ç­”æ¡ˆæå–å™¨
try:
    from .answer_extractor import AnswerExtractor
except ImportError:
    from answer_extractor import AnswerExtractor


class RewardComputer:
    """
    æ”¹è¿›çš„å¥–åŠ±è®¡ç®—å™¨

    æ–°å¢ç‰¹æ€§(å€Ÿé‰´ROLL):
    1. æ ¼å¼å¥–åŠ± - æ£€æŸ¥<think>/<answer>æ ‡ç­¾
    2. é‡å¤æƒ©ç½š - N-gramé‡å¤æ£€æµ‹
    3. æ”¹è¿›çš„æ•°å­¦è¯„ä¼° - æ”¯æŒLaTeXå’Œboxed
    4. æ›´ç»†ç²’åº¦çš„è¯„åˆ†é˜¶æ¢¯
    5. LLM Judge - ä½¿ç”¨GPT OSS 120Bè¿›è¡Œè¯­ä¹‰æ¯”è¾ƒ(AgentFlowæ–¹æ³•)
    """

    def __init__(
        self,
        reward_weights: Optional[Dict[str, float]] = None,
        use_answer_extractor: bool = True,  # æ˜¯å¦ä½¿ç”¨ç­”æ¡ˆæå–å™¨
        use_llm_judge: bool = False,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨LLM Judge
        llm_config: Optional[Dict] = None  # æ–°å¢ï¼šLLMé…ç½®
    ):
        """
        Args:
            reward_weights: å¥–åŠ±æƒé‡é…ç½®ï¼ˆä»…ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…ä½¿ç”¨äºŒå…ƒå¥–åŠ±ï¼‰
            use_answer_extractor: æ˜¯å¦ä½¿ç”¨ç­”æ¡ˆæå–å™¨æ¥æ ‡å‡†åŒ–ç­”æ¡ˆ
            use_llm_judge: æ˜¯å¦ä½¿ç”¨LLM Judgeè¿›è¡Œè¯­ä¹‰æ¯”è¾ƒ
            llm_config: LLMé…ç½®ï¼ˆç”¨äºLLM Judgeï¼‰
        """
        # ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œä½†ä¸å†ä½¿ç”¨
        self.reward_weights = reward_weights or {
            "correctness": 1.0
        }

        # åˆå§‹åŒ–ç­”æ¡ˆæå–å™¨
        self.use_answer_extractor = use_answer_extractor
        if use_answer_extractor:
            self.extractor = AnswerExtractor(use_llm_fallback=False)  # æš‚æ—¶ä¸ä½¿ç”¨LLMå…œåº•
        else:
            self.extractor = None

        # åˆå§‹åŒ–LLM Judge
        self.use_llm_judge = use_llm_judge
        self.llm_judge_client = None
        if use_llm_judge:
            self._init_llm_judge_client(llm_config)

        print(f"âœ… 10åˆ†åˆ¶å¥–åŠ±è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  æ¨¡å¼: æ­£ç¡®æ€§åˆ†æ•° [-10, 10] â†’ å½’ä¸€åŒ–å¥–åŠ± [0, 1]")
        print(f"  ç­”æ¡ˆæå–å™¨: {'å¯ç”¨' if use_answer_extractor else 'ç¦ç”¨'}")
        print(f"  LLM Judge: {'å¯ç”¨ (GPT OSS 120B @ port 8002)' if use_llm_judge else 'ç¦ç”¨'}")

    def _init_llm_judge_client(self, llm_config: Optional[Dict]):
        """åˆå§‹åŒ–LLM Judgeå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨GPT OSS 120Bï¼‰"""
        try:
            from openai import OpenAI

            # ä½¿ç”¨port 8002çš„GPT OSS 120Bæ¨¡å‹
            default_config = {
                "base_url": "http://localhost:8002/v1",
                "api_key": "sk-dummy",  # vLLMä¸éœ€è¦çœŸå®key
                "model_name": "/home/yijia/lhy/openai/gpt-oss-120b"  # å®Œæ•´æ¨¡å‹è·¯å¾„
            }

            config = llm_config or default_config

            self.llm_judge_client = OpenAI(
                base_url=config.get("base_url", default_config["base_url"]),
                api_key=config.get("api_key", default_config["api_key"])
            )
            self.llm_judge_model = config.get("model_name", default_config["model_name"])

            print(f"  âœ… LLM Judgeå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            print(f"     æ¨¡å‹: {self.llm_judge_model}")
            print(f"     URL: {config.get('base_url', default_config['base_url'])}")
        except Exception as e:
            print(f"  âš ï¸  LLM Judgeå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.use_llm_judge = False
            self.llm_judge_client = None

    def _llm_judge_compare(
        self,
        problem: str,
        prediction: str,
        ground_truth: str,
        problem_type: str
    ) -> bool:
        """
        ä½¿ç”¨LLM Judgeè¿›è¡Œè¯­ä¹‰æ¯”è¾ƒï¼ˆAgentFlowæ–¹æ³•ï¼‰

        Args:
            problem: é—®é¢˜æ–‡æœ¬
            prediction: æ¨¡å‹é¢„æµ‹ï¼ˆå®Œæ•´å“åº”ï¼Œæœªæå–ï¼‰
            ground_truth: Ground truthç­”æ¡ˆ
            problem_type: é—®é¢˜ç±»å‹

        Returns:
            bool: Trueè¡¨ç¤ºç­‰ä»·ï¼ŒFalseè¡¨ç¤ºä¸ç­‰ä»·
        """
        if not self.llm_judge_client:
            print("âš ï¸  LLM Judgeå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œé™çº§ä¸ºè§„åˆ™æ¯”è¾ƒ")
            return False

        # æ„å»ºAgentFlowé£æ ¼çš„promptï¼ˆä¼˜åŒ–ç‰ˆ - æ›´æ˜ç¡®çš„æå–æŒ‡å¯¼ï¼‰
        query_prompt = f"""You are a precise mathematical and logical equivalence evaluator. Your task is to determine if the Model Response contains an answer equivalent to the Ground Truth.

**Step 1: Extract the Final Answer**
From the Model Response, extract ONLY the final answer, ignoring all reasoning steps, explanations, and intermediate calculations.

Look for answers in these formats (in order of priority):
1. Inside `\\boxed{{...}}` LaTeX notation
2. After phrases like "The answer is", "Therefore", "So", "Thus", "Final answer:"
3. In `<answer>...</answer>` tags
4. The last number, expression, or entity mentioned

**Step 2: Extract from Ground Truth**
Similarly extract the final answer from Ground Truth, which may contain:
- Step-by-step solutions (extract only the final result)
- Multiple numbers (take the last/final one)
- Explanatory text (ignore and find the answer)

**Step 3: Normalize Both Answers**
Before comparing, normalize both answers:
- **Numbers:** Convert to same format (0.5 == 1/2 == 50%)
- **Units/Currency:** Ignore ($30 == 30, 10 meters == 10)
- **Formatting:** Ignore spaces, case, punctuation
- **LaTeX:** Interpret mathematical meaning (\\frac{{1}}{{2}} == 0.5)

**Step 4: Compare Equivalence**
Answers are equivalent if:
- **Math:** Numerically/algebraically equal (even if different forms)
- **Text:** Same entity/concept (ignore synonyms, case)
- **Precision:** Allow reasonable rounding (42.0 == 42)

**Examples of CORRECT equivalence:**
- "1/2" == "0.5" âœ“
- "$30" == "30" âœ“
- "\\boxed{{42}}" == "42" âœ“
- "x^2+2x+1" == "(x+1)^2" âœ“ (algebraically equivalent)
- "10 meters" == "10" âœ“

**Examples of INCORRECT equivalence:**
- "John Smith" == "Jane Doe" âœ— (different entities)
- "42" == "43" âœ— (different numbers)
- "Paris" == "London" âœ— (different locations)

**Inputs:**
Question: {problem}
Model Response: {prediction}
Ground Truth: {ground_truth}

**Required Output Format:**
<analysis>Your reasoning in 1-2 sentences</analysis>
<true_false>True or False</true_false>

Be LENIENT with formatting differences but STRICT with factual/numerical differences.
"""

        try:
            # è°ƒç”¨LLM Judgeï¼ˆæœ€å¤šé‡è¯•1æ¬¡ï¼‰
            for attempt in range(2):  # 0=é¦–æ¬¡, 1=é‡è¯•
                response = self.llm_judge_client.chat.completions.create(
                    model=self.llm_judge_model,
                    messages=[
                        {"role": "system", "content": "You are a precise answer equivalence evaluator."},
                        {"role": "user", "content": query_prompt}
                    ],
                    temperature=0.0,
                    max_tokens=200
                )

                # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                content = response.choices[0].message.content
                if content is None:
                    if attempt == 0:
                        print(f"âš ï¸  LLM Judgeé¦–æ¬¡è¿”å›ç©ºå†…å®¹ï¼Œé‡è¯•ä¸­...")
                        continue  # é‡è¯•
                    else:
                        print(f"âš ï¸  LLM Judgeé‡è¯•åä»è¿”å›ç©ºå†…å®¹ï¼Œfallbackåˆ¤å®šä¸ºFalse")
                        return False

                # æˆåŠŸè·å–å†…å®¹ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                result_text = content.strip()
                break

            # è§£æ<true_false>æ ‡ç­¾ - å¢å¼ºçš„é²æ£’æ€§åŒ¹é…
            import re
            # åŒ¹é…å¤šç§æ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§å°è¯•ï¼‰ï¼š
            # 1. <true_false>True</true_false>
            # 2. <true_false>: True
            # 3. **true_false**: True
            # 4. true_false: True
            # 5. ç›´æ¥åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾True/Falseï¼ˆæœ€åæ‰‹æ®µï¼‰

            # å°è¯•1: æ ‡å‡†XMLæ ‡ç­¾
            true_false_match = re.search(
                r'<true_false>\s*(True|False)\s*</true_false>',
                result_text,
                re.IGNORECASE
            )

            # å°è¯•2: å†’å·åˆ†éš”çš„æ ‡ç­¾
            if not true_false_match:
                true_false_match = re.search(
                    r'<true_false>\s*:\s*(True|False)',
                    result_text,
                    re.IGNORECASE
                )

            # å°è¯•3: Markdownç²—ä½“æ ¼å¼
            if not true_false_match:
                true_false_match = re.search(
                    r'\*\*true_false\*\*\s*:?\s*(True|False)',
                    result_text,
                    re.IGNORECASE
                )

            # å°è¯•4: ç®€å•çš„key: valueæ ¼å¼
            if not true_false_match:
                true_false_match = re.search(
                    r'true_false\s*:?\s*(True|False)',
                    result_text,
                    re.IGNORECASE
                )

            # å°è¯•5: æŸ¥æ‰¾ç‹¬ç«‹çš„True/Falseï¼ˆæœ€åæ‰‹æ®µï¼‰
            if not true_false_match:
                # åªåœ¨å“åº”æœ«å°¾æŸ¥æ‰¾ï¼Œé¿å…è¯¯åŒ¹é…åˆ†ææ–‡æœ¬ä¸­çš„True/False
                last_200_chars = result_text[-200:]
                true_false_match = re.search(
                    r'\b(True|False)\b',
                    last_200_chars,
                    re.IGNORECASE
                )

            if true_false_match:
                verdict = true_false_match.group(1).lower() == "true"

                # è°ƒè¯•è¾“å‡ºï¼ˆ20%é‡‡æ ·ï¼‰
                import random
                if random.random() < 0.2:
                    print(f"\nğŸ¤– LLM Judgeç»“æœ ({problem_type}):")
                    print(f"  é—®é¢˜: {problem[:60]}...")
                    print(f"  é¢„æµ‹: {str(prediction)[:60]}...")
                    print(f"  çœŸå€¼: {str(ground_truth)[:60]}...")
                    print(f"  åˆ¤å†³: {verdict}")
                    print(f"  LLMå“åº”: {result_text[:150]}...")

                return verdict
            else:
                # å®Œå…¨æ— æ³•è§£ææ—¶ï¼Œæ‰“å°å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
                print(f"âš ï¸  æ— æ³•è§£æLLM Judgeå“åº”ï¼ˆå°è¯•äº†5ç§æ ¼å¼ï¼‰")
                print(f"  å®Œæ•´å“åº”: {result_text}")
                return False

        except Exception as e:
            print(f"âš ï¸  LLM Judgeè°ƒç”¨å¤±è´¥: {e}")
            return False

    def compute_reward(
        self,
        problem: str,
        prediction: Any,
        ground_truth: Any,
        problem_type: str = "math",
        metadata: Optional[Dict] = None
    ) -> float:
        """
        è®¡ç®—å¥–åŠ± - æ”¯æŒLLM Judgeå’Œç­”æ¡ˆæå–ä¸¤ç§æ¨¡å¼

        Returns:
            reward: èŒƒå›´ [0.0, 1.0] (å½’ä¸€åŒ–åçš„å¥–åŠ±)
        """
        metadata = metadata or {}

        # ä½¿ç”¨LLM Judgeè¿›è¡Œè¯­ä¹‰æ¯”è¾ƒï¼ˆæ‰€æœ‰ä»»åŠ¡ç±»å‹ï¼‰
        is_correct = self._llm_judge_compare(
            problem=problem,
            prediction=str(prediction),
            ground_truth=str(ground_truth),
            problem_type=problem_type
        )

        # äºŒå…ƒå¥–åŠ±ï¼šæ­£ç¡®=10åˆ†ï¼Œé”™è¯¯=-5åˆ†
        correctness_score = 10.0 if is_correct else -5.0

        if metadata is not None:
            metadata['correctness_score'] = correctness_score
            metadata['used_llm_judge'] = True

        # å½’ä¸€åŒ–åˆ°[0, 1]ç”¨äºGRPO
        # ä½¿ç”¨ç®€å•çš„äºŒå…ƒæ˜ å°„ï¼Œé¿å…å¤æ‚çš„sigmoid
        normalized_reward = 1.0 if is_correct else 0.0

        return normalized_reward

    def _is_correct(
        self,
        prediction: Any,
        ground_truth: Any,
        problem_type: str
    ) -> bool:
        """
        åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®

        Returns:
            bool: True if correct, False otherwise
        """
        if prediction is None:
            return False

        if problem_type == "math":
            return self._is_math_correct(prediction, ground_truth)
        elif problem_type == "code":
            return self._is_code_correct(prediction, ground_truth)
        elif problem_type == "qa":
            return self._is_qa_correct(prediction, ground_truth)
        else:
            return self._is_general_correct(prediction, ground_truth)

    def _is_math_correct(self, prediction: str, ground_truth: str) -> bool:
        """
        åˆ¤æ–­æ•°å­¦ç­”æ¡ˆæ˜¯å¦æ­£ç¡®

        æ”¯æŒ:
        - æ•°å­—æ¯”è¾ƒï¼ˆå«æµ®ç‚¹è¯¯å·®ï¼‰
        - åˆ†æ•°æ¯”è¾ƒï¼ˆå¦‚ 5/324 vs 0.0154...ï¼‰
        - å­—ç¬¦ä¸²åŒ¹é…
        """
        try:
            pred_str = str(prediction).strip()
            gt_str = str(ground_truth).strip()

            # å­—ç¬¦ä¸²å®Œå…¨åŒ¹é…
            if pred_str == gt_str:
                return True

            # è§£æä¸ºæ•°å€¼æ¯”è¾ƒï¼ˆæ”¯æŒåˆ†æ•°ï¼‰
            def parse_number(s: str) -> float:
                """è§£ææ•°å­—ï¼Œæ”¯æŒåˆ†æ•°æ ¼å¼"""
                if '/' in s:
                    parts = s.split('/')
                    return float(parts[0]) / float(parts[1])
                return float(s)

            try:
                pred_num = parse_number(pred_str)
                gt_num = parse_number(gt_str)

                # ä½¿ç”¨ç›¸å¯¹è¯¯å·®æ¯”è¾ƒï¼ˆå¤„ç†æµ®ç‚¹ç²¾åº¦ï¼‰
                rel_error = abs(pred_num - gt_num) / (abs(gt_num) + 1e-9)
                return rel_error < 1e-6
            except:
                pass

            # æ–¹æ³•1: boxed æ ¼å¼
            pred_boxed = self._extract_boxed(pred_str)
            gt_boxed = self._extract_boxed(gt_str)
            if pred_boxed and gt_boxed:
                try:
                    pred_num = parse_number(pred_boxed)
                    gt_num = parse_number(gt_boxed)
                    rel_error = abs(pred_num - gt_num) / (abs(gt_num) + 1e-9)
                    if rel_error < 1e-6:
                        return True
                except:
                    pass

            # æ–¹æ³•2: æ•°å­—æå–
            pred_numbers = self._extract_numbers(pred_str)
            gt_numbers = self._extract_numbers(gt_str)

            if not gt_numbers:
                # æ— æ³•æå–æ•°å­—ï¼Œç”¨å­—ç¬¦ä¸²åŒ¹é…
                return gt_str.strip().lower() in pred_str.strip().lower()

            if not pred_numbers:
                return False

            # æ¯”è¾ƒæœ€åä¸€ä¸ªæ•°å­—
            pred_answer = pred_numbers[-1]
            gt_answer = gt_numbers[-1]

            return abs(pred_answer - gt_answer) < 1e-4

        except Exception:
            return False

    def _is_code_correct(self, prediction: str, ground_truth: str) -> bool:
        """åˆ¤æ–­ä»£ç ç­”æ¡ˆæ˜¯å¦æ­£ç¡®"""
        try:
            pred_str = str(prediction).strip()
            gt_str = str(ground_truth).strip()

            if not pred_str:
                return False

            # ç²¾ç¡®åŒ¹é…
            if pred_str.lower() == gt_str.lower():
                return True

            # åŒ…å«åŒ¹é…
            if gt_str.lower() in pred_str.lower():
                return True

            return False

        except Exception:
            return False

    def _is_qa_correct(self, prediction: str, ground_truth: str) -> bool:
        """åˆ¤æ–­QAç­”æ¡ˆæ˜¯å¦æ­£ç¡®"""
        try:
            pred_str = str(prediction).strip().lower()
            gt_str = str(ground_truth).strip().lower()

            # ç²¾ç¡®åŒ¹é…
            if pred_str == gt_str:
                return True

            # åŒ…å«åŒ¹é…
            if gt_str in pred_str or pred_str in gt_str:
                return True

            # Tokené‡å é˜ˆå€¼
            pred_tokens = set(pred_str.split())
            gt_tokens = set(gt_str.split())

            if len(gt_tokens) == 0:
                return False

            overlap_ratio = len(pred_tokens & gt_tokens) / len(gt_tokens)
            return overlap_ratio > 0.8

        except Exception:
            return False

    def _is_general_correct(self, prediction: str, ground_truth: str) -> bool:
        """é€šç”¨æ­£ç¡®æ€§åˆ¤æ–­"""
        try:
            pred_str = str(prediction).strip().lower()
            gt_str = str(ground_truth).strip().lower()

            return pred_str == gt_str or gt_str in pred_str

        except Exception:
            return False

    def _compute_correctness_reward(
        self,
        prediction: Any,
        ground_truth: Any,
        problem_type: str
    ) -> float:
        """
        è®¡ç®—æ­£ç¡®æ€§å¥–åŠ±ï¼ˆä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰

        Returns:
            reward: [-10, 10]
        """
        if prediction is None:
            return -10.0  # æ‰§è¡Œå¤±è´¥

        if problem_type == "math":
            return self._compute_math_correctness(prediction, ground_truth)
        elif problem_type == "code":
            return self._compute_code_correctness(prediction, ground_truth)
        elif problem_type == "qa":
            return self._compute_qa_correctness(prediction, ground_truth)
        else:
            return self._compute_general_correctness(prediction, ground_truth)

    def _compute_math_correctness(self, prediction: str, ground_truth: str) -> float:
        """
        æ•°å­¦é—®é¢˜æ­£ç¡®æ€§(æ”¹è¿›ç‰ˆ - å€Ÿé‰´ROLL)

        æ”¹è¿›:
        1. æ”¯æŒLaTeX \boxed{}æ ¼å¼
        2. æ›´ç»†ç²’åº¦çš„è¯„åˆ†é˜¶æ¢¯
        3. æ›´å¥½çš„æ•°å­—æå–
        """
        try:
            pred_str = str(prediction)
            gt_str = str(ground_truth)

            # æ–¹æ³•1: æå–boxedç­”æ¡ˆ(ROLLé£æ ¼)
            pred_boxed = self._extract_boxed(pred_str)
            gt_boxed = self._extract_boxed(gt_str)

            if pred_boxed and gt_boxed:
                try:
                    pred_num = float(pred_boxed)
                    gt_num = float(gt_boxed)
                    diff = abs(pred_num - gt_num)

                    if diff < 1e-4:
                        return 10.0   # å®Œå…¨æ­£ç¡®
                    elif diff < 0.1:
                        return 8.0    # éå¸¸æ¥è¿‘(æ–°å¢é˜¶æ¢¯)
                    elif diff < 1.0:
                        return 5.0    # æ¥è¿‘
                    elif diff < 10.0:
                        return 2.0    # æ•°é‡çº§æ­£ç¡®(æ–°å¢é˜¶æ¢¯)
                    else:
                        return -5.0   # é”™è¯¯
                except:
                    pass

            # æ–¹æ³•2: æ•°å­—æå–(æ”¹è¿›ç‰ˆ)
            pred_numbers = self._extract_numbers(pred_str)
            gt_numbers = self._extract_numbers(gt_str)

            if not gt_numbers:
                # æ— æ³•æå–ground truthæ•°å­—,ä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…
                if gt_str.strip().lower() in pred_str.strip().lower():
                    return 10.0
                else:
                    return -5.0

            if not pred_numbers:
                # æ— æ³•æå–é¢„æµ‹æ•°å­—
                return -8.0

            # å–æœ€åä¸€ä¸ªæ•°å­—ä½œä¸ºç­”æ¡ˆ
            pred_answer = pred_numbers[-1]
            gt_answer = gt_numbers[-1]

            # æ¯”è¾ƒ(æ›´ç»†ç²’åº¦)
            diff = abs(pred_answer - gt_answer)

            if diff < 1e-4:
                return 10.0   # å®Œå…¨æ­£ç¡®
            elif diff < 0.1:
                return 8.0    # éå¸¸æ¥è¿‘
            elif diff < 1.0:
                return 5.0    # æ¥è¿‘
            elif diff < 10.0:
                return 2.0    # æ•°é‡çº§æ­£ç¡®
            else:
                return -5.0   # é”™è¯¯

        except Exception as e:
            print(f"âš ï¸  æ•°å­¦è¯„ä¼°é”™è¯¯: {e}")
            return -5.0

    def _extract_boxed(self, text: str) -> Optional[str]:
        """æå–\boxed{}ä¸­çš„å†…å®¹(ROLLé£æ ¼)"""
        match = re.search(r'\\boxed\{([^}]+)\}', text)
        if match:
            return match.group(1).strip()
        return None

    def _extract_numbers(self, text: str) -> list:
        """ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰æ•°å­—(æ”¹è¿›ç‰ˆ + æ–‡å­—æ•°å­—è¯†åˆ«)"""
        numbers = []

        # Method 1: Numeric extraction (existing)
        # åŒ¹é…æ•´æ•°ã€å°æ•°ã€è´Ÿæ•°ã€ç§‘å­¦è®¡æ•°æ³•
        pattern = r'-?\d+\.?\d*(?:[eE][+-]?\d+)?'
        matches = re.findall(pattern, text)
        for m in matches:
            if m:
                try:
                    numbers.append(float(m))
                except:
                    pass

        # Method 2: Word-to-number recognition (NEW - fixes ~15-20% QA errors)
        # Aligns with SQuAD/HotpotQA standards for text-based answers
        word_to_num = {
            'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4,
            'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9,
            'ten': 10, 'eleven': 11, 'twelve': 12, 'thirteen': 13,
            'fourteen': 14, 'fifteen': 15, 'sixteen': 16, 'seventeen': 17,
            'eighteen': 18, 'nineteen': 19, 'twenty': 20, 'thirty': 30,
            'forty': 40, 'fifty': 50, 'sixty': 60, 'seventy': 70,
            'eighty': 80, 'ninety': 90, 'hundred': 100, 'thousand': 1000
        }

        text_lower = text.lower()
        for word, num in word_to_num.items():
            if word in text_lower:
                numbers.append(float(num))

        return numbers

    def _compute_code_correctness(self, prediction: str, ground_truth: str) -> float:
        """
        ä»£ç é—®é¢˜æ­£ç¡®æ€§(æ”¹è¿›ç‰ˆ)

        æ”¹è¿›è¯´æ˜ï¼š
        - åŒºåˆ†fallbackå ä½ç¬¦ (è¿”å›-3.0) vs çœŸæ­£çš„ç©ºé¢„æµ‹ (è¿”å›-10.0)
        - fallbackå ä½ç¬¦è¡¨ç¤ºè‡³å°‘å°è¯•äº†ï¼Œç»™äºˆéƒ¨åˆ†å­¦ä¹ ä¿¡å·
        - çœŸæ­£çš„ç©ºé¢„æµ‹è¯´æ˜å½»åº•å¤±è´¥ï¼Œç»™äºˆä¸¥å‰æƒ©ç½š
        """
        try:
            pred_str = str(prediction).strip()
            gt_str = str(ground_truth).strip()

            # å¦‚æœé¢„æµ‹ä¸ºç©º
            if not pred_str:
                return -10.0  # å½»åº•å¤±è´¥

            # æ£€æŸ¥æ˜¯å¦ä¸ºfallbackå ä½ç¬¦
            if "[Fallback placeholder for problem:" in pred_str:
                # Fallbackæœºåˆ¶æˆåŠŸè§¦å‘ï¼Œè‡³å°‘è¿”å›äº†æŸäº›å†…å®¹
                # ç»™äºˆéƒ¨åˆ†å­¦ä¹ ä¿¡å·ï¼Œè€Œä¸æ˜¯å®Œå…¨æƒ©ç½š
                return -3.0

            # å®Œå…¨åŒ¹é…(æœ€é«˜åˆ†)
            if pred_str.lower() == gt_str.lower():
                return 10.0

            # åŒ…å«åŒ¹é…
            if gt_str.lower() in pred_str.lower():
                return 10.0

            # æå–å‡½æ•°å®šä¹‰
            pred_funcs = self._extract_function_names(pred_str)
            gt_funcs = self._extract_function_names(gt_str)

            # æ£€æŸ¥å‡½æ•°åæ˜¯å¦åŒ¹é…
            if pred_funcs and gt_funcs:
                if any(pf == gf for pf in pred_funcs for gf in gt_funcs):
                    return 5.0  # éƒ¨åˆ†æ­£ç¡®

            # æ£€æŸ¥æ˜¯å¦è‡³å°‘åŒ…å«Pythonä»£ç ç‰¹å¾
            if "def " in pred_str and ("return" in pred_str or "print" in pred_str):
                # è‡³å°‘çœ‹èµ·æ¥åƒä»£ç ï¼Œç»™äºˆä¸­ç­‰æƒ©ç½š
                return -2.0

            return -5.0

        except Exception as e:
            print(f"âš ï¸  ä»£ç è¯„ä¼°é”™è¯¯: {e}")
            return -5.0

    def _extract_function_names(self, code: str) -> list:
        """ä»ä»£ç ä¸­æå–å‡½æ•°å"""
        pattern = r'def\s+(\w+)\s*\('
        matches = re.findall(pattern, code)
        return matches

    def _compute_qa_correctness(self, prediction: str, ground_truth: str) -> float:
        """
        QAé—®é¢˜æ­£ç¡®æ€§(ROLLé£æ ¼æ”¹è¿›)
        """
        try:
            pred_str = str(prediction).strip().lower()
            gt_str = str(ground_truth).strip().lower()

            if not pred_str:
                return -10.0

            # ç²¾ç¡®åŒ¹é…
            if pred_str == gt_str:
                return 10.0

            # åŒ…å«åŒ¹é…
            if gt_str in pred_str:
                return 8.0

            # Tokené‡å 
            pred_tokens = set(pred_str.split())
            gt_tokens = set(gt_str.split())

            if not gt_tokens:
                return -5.0

            overlap_ratio = len(pred_tokens & gt_tokens) / len(gt_tokens)

            if overlap_ratio > 0.8:
                return 6.0
            elif overlap_ratio > 0.5:
                return 3.0
            elif overlap_ratio > 0.2:
                return 0.0
            else:
                return -5.0

        except Exception as e:
            print(f"âš ï¸  QAè¯„ä¼°é”™è¯¯: {e}")
            return -5.0

    def _compute_general_correctness(self, prediction: str, ground_truth: str) -> float:
        """é€šç”¨æ­£ç¡®æ€§è¯„ä¼°"""
        return self._compute_qa_correctness(prediction, ground_truth)

    def _compute_efficiency_reward(self, cost: float) -> float:
        """
        è®¡ç®—æ•ˆç‡å¥–åŠ±(åŸºäºAPIæˆæœ¬) - ROLLé£æ ¼

        Returns:
            reward: [-8, 10]
        """
        if cost == 0.0:
            return 0.0

        # ROLLé£æ ¼çš„æˆæœ¬é˜ˆå€¼
        if cost <= 0.001:
            return 10.0
        elif cost <= 0.005:
            return 5.0
        elif cost <= 0.01:
            return 0.0
        elif cost <= 0.05:
            return -3.0
        else:
            return -8.0

    def _compute_simplicity_reward(
        self,
        execution_time: float,
        num_operators: int = 1
    ) -> float:
        """
        è®¡ç®—ç®€æ´æ€§å¥–åŠ± - ROLLé£æ ¼

        Returns:
            reward: [-5, 10]
        """
        # åŸºäºæ‰§è¡Œæ—¶é—´
        if execution_time <= 5.0:
            time_reward = 10.0
        elif execution_time <= 15.0:
            time_reward = 5.0
        elif execution_time <= 30.0:
            time_reward = 0.0
        elif execution_time <= 60.0:
            time_reward = -3.0
        else:
            time_reward = -5.0

        # åŸºäºç®—å­æ•°é‡
        if num_operators <= 2:
            operator_reward = 10.0
        elif num_operators <= 4:
            operator_reward = 5.0
        elif num_operators <= 6:
            operator_reward = 0.0
        else:
            operator_reward = -5.0

        # å¹³å‡
        return (time_reward + operator_reward) / 2.0

    def _compute_format_reward(self, response: str, problem_type: str) -> float:
        """
        æ ¼å¼å¥–åŠ±(æ–°å¢ - ROLLé£æ ¼)

        æ£€æŸ¥å“åº”æ ¼å¼è§„èŒƒæ€§

        Returns:
            reward: [-2, 2]
        """
        if not response:
            return -2.0

        if problem_type == "math":
            # æ£€æŸ¥æ˜¯å¦æœ‰æ€è€ƒè¿‡ç¨‹+ç­”æ¡ˆ
            has_think = bool(re.search(r'<think>.*?</think>', response, re.DOTALL))
            has_answer = bool(re.search(r'<answer>.*?</answer>', response, re.DOTALL))

            if has_think and has_answer:
                return 2.0    # å®Œç¾æ ¼å¼
            elif has_answer:
                return 0.0    # åŸºæœ¬æ ¼å¼
            else:
                return -2.0   # æ ¼å¼æ··ä¹±

        elif problem_type == "code":
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç å—
            has_code_block = bool(re.search(r'```.*?```', response, re.DOTALL))

            if has_code_block:
                return 2.0
            else:
                return -2.0

        elif problem_type == "qa":
            # æ£€æŸ¥ç­”æ¡ˆé•¿åº¦åˆç†æ€§
            if 10 < len(response) < 500:
                return 2.0
            elif len(response) > 0:
                return 0.0
            else:
                return -2.0

        return 0.0

    def _compute_repetition_penalty(self, response: str, ngram_size: int = 3) -> float:
        """
        é‡å¤æƒ©ç½š(æ–°å¢ - ROLLé£æ ¼)

        è®¡ç®—N-gramé‡å¤åº¦å¹¶ç»™äºˆæƒ©ç½š

        Args:
            response: å“åº”æ–‡æœ¬
            ngram_size: N-gramå¤§å°(é»˜è®¤3)

        Returns:
            penalty: [-2, 0]
        """
        if not response:
            return 0.0

        words = response.split()

        if len(words) < ngram_size:
            return 0.0

        # ç”Ÿæˆæ‰€æœ‰N-grams
        ngrams = []
        for i in range(len(words) - ngram_size + 1):
            ngram = tuple(words[i:i+ngram_size])
            ngrams.append(ngram)

        if not ngrams:
            return 0.0

        # è®¡ç®—å”¯ä¸€N-gramsæ¯”ä¾‹
        unique_ratio = len(set(ngrams)) / len(ngrams)

        # è½¬æ¢ä¸ºæƒ©ç½š
        if unique_ratio > 0.9:
            return 0.0      # å‡ ä¹æ— é‡å¤
        elif unique_ratio > 0.7:
            return -0.5     # è½»å¾®é‡å¤
        elif unique_ratio > 0.5:
            return -1.0     # ä¸­åº¦é‡å¤
        else:
            return -2.0     # ä¸¥é‡é‡å¤


def test_reward_computer():
    """æµ‹è¯•æ”¹è¿›ç‰ˆå¥–åŠ±è®¡ç®—å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•æ”¹è¿›ç‰ˆå¥–åŠ±è®¡ç®—å™¨")
    print("=" * 60)

    computer = RewardComputer()

    # æµ‹è¯•æ¡ˆä¾‹
    test_cases = [
        {
            "name": "æ•°å­¦ - å®Œç¾æ ¼å¼+æ­£ç¡®",
            "problem": "What is 15 + 27?",
            "prediction": "<think>Let me calculate: 15 + 27 = 42</think><answer>\\boxed{42}</answer>",
            "ground_truth": "42",
            "problem_type": "math",
            "metadata": {"cost": 0.002, "execution_time": 3.5}
        },
        {
            "name": "æ•°å­¦ - æ­£ç¡®ä½†æ— æ ¼å¼",
            "problem": "What is 15 + 27?",
            "prediction": "The answer is 42.",
            "ground_truth": "42",
            "problem_type": "math",
            "metadata": {"cost": 0.002, "execution_time": 3.0}
        },
        {
            "name": "æ•°å­¦ - æ¥è¿‘ç­”æ¡ˆ",
            "problem": "What is 15 + 27?",
            "prediction": "<think>Calculating</think><answer>42.1</answer>",
            "ground_truth": "42",
            "problem_type": "math",
            "metadata": {"cost": 0.001, "execution_time": 2.0}
        },
        {
            "name": "ä»£ç  - æ­£ç¡®+æ ¼å¼",
            "problem": "Write a function to square a number",
            "prediction": "```python\ndef square(x):\n    return x * x\n```",
            "ground_truth": "def square(x):\n    return x * x",
            "problem_type": "code",
            "metadata": {"cost": 0.003, "execution_time": 5.0}
        },
        {
            "name": "QA - æ­£ç¡®",
            "problem": "What is the capital of France?",
            "prediction": "The capital of France is Paris.",
            "ground_truth": "Paris",
            "problem_type": "qa",
            "metadata": {"cost": 0.001, "execution_time": 2.0}
        },
        {
            "name": "ä¸¥é‡é‡å¤",
            "problem": "Test",
            "prediction": "answer answer answer answer answer answer",
            "ground_truth": "answer",
            "problem_type": "qa",
            "metadata": {"cost": 0.001, "execution_time": 1.0}
        }
    ]

    for case in test_cases:
        reward = computer.compute_reward(
            problem=case["problem"],
            prediction=case["prediction"],
            ground_truth=case["ground_truth"],
            problem_type=case["problem_type"],
            metadata=case["metadata"]
        )

        print(f"\nğŸ“ {case['name']}")
        print(f"  é¢„æµ‹: {case['prediction'][:60]}...")
        print(f"  æ­£ç¡®ç­”æ¡ˆ: {case['ground_truth']}")
        print(f"  å¥–åŠ±: {reward:.2f}/10.0")


if __name__ == "__main__":
    test_reward_computer()
