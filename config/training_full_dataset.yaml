# AFlow + ROLL 完整数据集训练配置 (GPU 2)
# 基于184K混合数据集进行优化

# 实验配置
exp_name: "aflow_grpo_full_dataset_fixed_code_v2"  # 完整数据集 + Code修复
output_dir: "checkpoints"
log_dir: "logs"
max_steps: 500                # 总训练步数
save_every: 50                # 每N步保存一次
eval_every: 10                # 每N步在验证集评估一次
val_samples: 100              # 验证集样本数量（增加到100）
log_every: 5                  # 每N步记录一次

# GRPO算法配置
adv_estimator: "grpo"
num_return_sequences_in_group: 4  # GRPO组大小：每个问题生成4个工作流
ppo_epochs: 1                      # 在线学习：每个batch只训练一次
async_generation_ratio: 0          # 同步模式：0表示完全同步
use_kl_loss: true
kl_loss_coef: 0.001
clip_range: 0.2
gamma: 1.0                         # 折扣因子
lambda_gae: 0.95                   # GAE lambda

# Batch配置 - 为大规模数据集优化
rollout_batch_size: 4              # 每批问题数
prompt_max_length: 3072            # 提示词最大长度
response_max_length: 5120          # 输出最大长度

# 模型配置
base_model: "/home/yijia/verl-agent/models/qwen/Qwen2___5-7B-Instruct"
model_dtype: "bfloat16"

# LoRA配置
use_lora: true
lora_rank: 64
lora_alpha: 64
lora_target_modules: "q_proj,k_proj,v_proj,o_proj"
lora_dropout: 0.05

# 训练参数
learning_rate: 1.0e-5
weight_decay: 0.01
max_grad_norm: 1.0
gradient_accumulation_steps: 2
warmup_steps: 50
bf16: true
gradient_checkpointing: false

# GPU配置 - GPU 2 专用
device_mapping: [0]                # 逻辑设备0（CUDA_VISIBLE_DEVICES=2后对应物理GPU 2）
physical_gpus: [2]                 # 实际使用的物理GPU 2
num_gpus: 1
world_size: 1

# 数据集配置 - 完整的184K混合数据集
data_dir: "data"
train_dataset: "data/train/mixed_dataset.jsonl"
val_dataset: "data/val/mixed_dataset.jsonl"
test_dataset: "data/test/mixed_dataset.jsonl"

# 混合采样比例
domain_ratios:
  math: 0.4      # 40% 数学问题
  code: 0.3      # 30% 代码问题
  qa: 0.3        # 30% QA问题

# AFlow配置
aflow_config_path: "config/aflow_llm.yaml"
aflow_operators: ["Custom", "AnswerGenerate", "Programmer", "ScEnsemble", "Test", "Review", "Revise"]
aflow_operator_descriptions_path: "/home/yijia/.claude/11/AFlow/workspace/MATH/workflows/template/operator.json"
execution_timeout: 180

# 奖励配置
reward_weights:
  correctness: 0.65   # 正确性权重
  efficiency: 0.15    # 效率权重（成本）
  simplicity: 0.10    # 简洁性权重（算子数）
  format: 0.05        # 格式奖励
  repetition: 0.05    # 重复惩罚

# ExperienceBuffer - 高质量样本管理
experience_buffer:
  enabled: true
  buffer_size: 100                # 每个问题类型保留的最大样本数
  reward_threshold: 8.0           # 高质量样本的奖励阈值
  persistence_dir: "data/experience_buffer"

# PromptOptimizer - Layer 1: Workflow生成提示词优化 ✅ 已修复
prompt_optimizer:
  enabled: true                   # ✅ 已启用动态提示词优化
  few_shot_k: 3                   # Few-shot示例数量
  similarity_threshold: 0.7       # 相似度阈值

# OperatorPromptEnhancer - Layer 2: Operator执行提示词增强
operator_prompt_enhancer:
  enabled: true
  top_k_examples: 2

# 监控配置
wandb:
  enabled: true
  project: "agent-prompt"
  entity: "yao110002-sdfsdfsdfsdf-com"
  api_key: "b42ca0000cf06f97b05eba34f58823ad5f3122a4"
  run_name: null  # 自动生成

# 生成配置
generation_config:
  temperature: 0.1
  top_p: 0.95
  top_k: 50
  max_new_tokens: 4096
  do_sample: true

# 调试选项
debug: false
verbose: true
