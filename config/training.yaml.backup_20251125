# AFlow + ROLL é›†æˆè®­ç»ƒé…ç½®
# ğŸ”¥ K=3, B=8, T=0.55 è´¨é‡+å¤šæ ·æ€§å¹³è¡¡é…ç½®
# ä¿®æ”¹æ—¶é—´: 2024-11-24
# é…ç½®ç†å¿µ: K=3æ›´æ˜“ä¿æŒå¤šæ ·æ€§ï¼ŒT=0.55å¹³è¡¡è´¨é‡ä¸æ¢ç´¢

# å®éªŒé…ç½®
exp_name: "aflow_grpo_k3_b8_temp055_v1"  # K=3 + T=0.55é…ç½®
output_dir: "checkpoints"
log_dir: "logs"
max_steps: 500
save_every: 50
eval_every: 999999
val_samples: 87
log_every: 5

# =====================================
# GRPOç®—æ³•é…ç½®
# =====================================
adv_estimator: "grpo"
num_return_sequences_in_group: 3  # ğŸ”¥ K=3ï¼ˆæ›´æ˜“ä¿æŒå¤šæ ·æ€§ï¼‰
ppo_epochs: 1
async_generation_ratio: 0
use_kl_loss: true
kl_loss_coef: 0.011                # ğŸ”¥ T=0.55é€‚åº¦KLçº¦æŸ
clip_range: 0.20
gamma: 1.0
lambda_gae: 0.95

# =====================================
# Batché…ç½®
# =====================================
rollout_batch_size: 8              # ğŸ”¥ K=3Ã—8=24æ ·æœ¬/step
prompt_max_length: 3072
response_max_length: 5120

# æ¨¡å‹é…ç½®
base_model: "/home/yijia/verl-agent/models/qwen/Qwen2___5-7B-Instruct"
model_dtype: "bfloat16"

# =====================================
# LoRAé…ç½®
# =====================================
use_lora: true
lora_rank: 64
lora_alpha: 64
lora_target_modules: "q_proj,k_proj,v_proj,o_proj"
lora_dropout: 0.05

# =====================================
# è®­ç»ƒå‚æ•°ï¼ˆé’ˆå¯¹T=0.55ä¼˜åŒ–ï¼‰
# =====================================
learning_rate: 5.0e-6              # ğŸ”¥ T=0.55ç•¥é«˜æ¸©åº¦ï¼Œæ¢å¤æ ‡å‡†LR
weight_decay: 0.01
max_grad_norm: 0.5
gradient_accumulation_steps: 2     # ğŸ”¥ æœ‰æ•ˆbatch=48æ ·æœ¬
warmup_steps: 50
bf16: true
gradient_checkpointing: false

# GPUé…ç½®
device_mapping: [0]
physical_gpus: [2]
protected_pids: []
num_gpus: 1
world_size: 1

# æ•°æ®é›†é…ç½®
data_dir: "data"
train_dataset: "11/integrated_aflow_roll/data/ready_to_train/train_final_clean.jsonl"
val_dataset: "11/integrated_aflow_roll/data/ready_to_train/test.jsonl"
test_dataset: "11/integrated_aflow_roll/data/ready_to_train/test.jsonl"

# æ··åˆé‡‡æ ·æ¯”ä¾‹
domain_ratios:
  math: 0.4
  code: 0.3
  qa: 0.3

# AFlowé…ç½®
aflow_config_path: "config/aflow_llm.yaml"
aflow_executor_model: "gpt-oss-120b"
aflow_operators: ["Custom", "AnswerGenerate", "Programmer", "ScEnsemble", "Test", "Review", "Revise"]
aflow_operator_descriptions_path: "/home/yijia/.claude/11/AFlow/workspace/MATH/workflows/template/operator.json"
execution_timeout: 600

# =====================================
# å¥–åŠ±é…ç½®ï¼ˆä¿æŒåŸå€¼ï¼‰
# =====================================
reward_weights:
  correctness: 0.65
  efficiency: 0.15
  simplicity: 0.10
  format: 0.05
  repetition: 0.05

# æç¤ºè¯ä¼˜åŒ–ç³»ç»Ÿ
experience_buffer:
  enabled: true
  buffer_size: 100
  reward_threshold: 8.0
  persistence_dir: "data/experience_buffer"

prompt_optimizer:
  enabled: true
  few_shot_k: 3
  similarity_threshold: 0.7

operator_prompt_enhancer:
  enabled: true
  top_k_examples: 2

# ç›‘æ§é…ç½®
wandb:
  enabled: true
  project: "agent-prompt"
  entity: "yao110002-sdfsdfsdfsdf-com"
  api_key: "b42ca0000cf06f97b05eba34f58823ad5f3122a4"
  run_name: null

# =====================================
# Temperatureè°ƒåº¦ï¼ˆç¦ç”¨ï¼‰
# =====================================
temperature_schedule:
  enabled: false
  initial: 0.55
  final: 0.55
  warmup_steps: 0

# =====================================
# ç”Ÿæˆé…ç½®ï¼ˆæ ¸å¿ƒï¼šæ¸©åº¦0.55ï¼‰
# =====================================
generation_config:
  temperature: 0.55                # ğŸ”¥ æ¸©åº¦0.55ï¼ˆè´¨é‡+å¤šæ ·æ€§å¹³è¡¡ï¼‰
  top_p: 0.93                      # ğŸ”¥ ç•¥æ”¾å®½ï¼ˆæ”¯æŒT=0.55ï¼‰
  top_k: 48                        # ğŸ”¥ é€‚åº¦å€™é€‰æ± 
  max_new_tokens: 4096
  do_sample: true

# è°ƒè¯•é€‰é¡¹
debug: false
verbose: true
