#!/bin/bash
echo "ğŸ”§ å¯åŠ¨ vLLM (å®‰å…¨æ¨¡å¼)..."

# æ¸…ç†ç¯å¢ƒ
export VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1
export CUDA_VISIBLE_DEVICES=3
export TOKENIZERS_PARALLELISM=false

# ç”¨æ ‡å‡†é…ç½®å¯åŠ¨
python3 -m vllm.entrypoints.openai.api_server \
  --model /home/yijia/lhy/openai/gpt-oss-120b \
  --port 8002 \
  --tensor-parallel-size 1 \
  --gpu-memory-utilization 0.7 \
  --max-model-len 2048 \
  --dtype bfloat16 \
  --disable-log-requests \
  2>&1 | tee logs/vllm_safe.log &

echo "âœ… vLLM å·²å¯åŠ¨ (PID: $!)"
sleep 60
echo "ğŸ”„ éªŒè¯ vLLM å¥åº·çŠ¶æ€..."
curl -s http://localhost:8002/v1/models 2>&1 | grep -q "data" && echo "âœ… vLLM å¥åº·" || echo "âŒ vLLM å¼‚å¸¸"
