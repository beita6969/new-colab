# 验证集评估功能说明

**添加日期**: 2025-11-18
**功能**: 每10步在验证集上评估模型泛化性能

---

## 📋 功能概览

### 问题背景

**之前的问题**:
- 所有准确率指标都在训练集上计算
- 无法了解模型的真实泛化能力
- 可能出现过拟合而不自知

**解决方案**:
- ✅ 每10步自动在验证集评估
- ✅ 使用50个验证样本
- ✅ 独立的验证指标（val_accuracy, val_avg_correctness等）
- ✅ 自动记录到wandb

---

## 🎯 核心功能

### 1. 自动验证评估

**触发频率**: 每10个训练步骤
**样本数量**: 50个验证集样本
**评估内容**: 与训练集相同的完整流程

### 2. 验证指标

| 指标 | 说明 | 取值范围 |
|------|------|---------|
| `val_accuracy` | 验证集准确率 | 0-100% |
| `val_num_correct` | 正确样本数 | 0-50 |
| `val_num_total` | 总样本数 | 50 |
| `val_avg_correctness` | 平均正确性评分 | 0-10 |
| `val_avg_cost` | 平均执行成本 | $0.00+ |
| `val_success_rate` | 执行成功率 | 0-100% |

### 3. WandB监控

所有验证指标自动记录到WandB：
- 可视化 `val_accuracy` vs `accuracy` 对比
- 监控训练集/验证集差距（泛化gap）
- 及时发现过拟合

---

## 🔧 配置参数

### training.yaml配置

```yaml
# 实验配置
max_steps: 500
save_every: 50
eval_every: 10     # 每N步在验证集评估（新增）
val_samples: 50    # 验证集样本数量（新增）
log_every: 5
```

### 配置说明

**eval_every** (默认: 10)
- 验证评估频率
- 10: 每10步评估一次（推荐）
- 5: 更频繁，但增加训练时间
- 20: 较少评估，加快训练

**val_samples** (默认: 50)
- 验证集样本数量
- 50: 平衡准确性和速度（推荐）
- 100: 更准确但更慢
- 20-30: 快速验证

---

## 📊 训练日志示例

### Step 10（首次验证）

```
============================================================
📍 Step 10/500
============================================================

[训练过程...]

📊 Metrics:
  loss: 0.0023
  accuracy: 87.5%
  ...

============================================================
🧪 验证集评估 (50个样本)
============================================================
📦 验证集分布: {'math': 20, 'code': 15, 'qa': 15}

验证集评估: 100%|████████████████| 50/50
  ✅ [1/50] 正确性: 10.0/10.0
  ✅ [2/50] 正确性: 9.5/10.0
  ❌ [3/50] 正确性: 3.0/10.0
  ✅ [4/50] 正确性: 8.5/10.0
  ✅ [5/50] 正确性: 10.0/10.0

📊 验证集结果:
  准确率: 38/50 = 76.0%
  平均正确性: 7.45/10.0
  执行成功率: 96.0%
  平均成本: $0.0023
============================================================

✅ 验证集评估完成 (Step 10)
```

### 关键观察

**训练集 vs 验证集对比**:
```
Step 10:
  训练集准确率: 87.5%
  验证集准确率: 76.0%
  泛化gap: 11.5%  ← 正常范围，模型在学习中

Step 50:
  训练集准确率: 94.0%
  验证集准确率: 91.5%
  泛化gap: 2.5%   ← 良好泛化

Step 100:
  训练集准确率: 98.0%
  验证集准确率: 89.0%
  泛化gap: 9.0%   ← ⚠️ 可能过拟合，考虑提前停止
```

---

## 📈 WandB可视化

### 创建对比图表

**在WandB中添加自定义图表**:

1. **训练集 vs 验证集准确率**:
   - X轴: step
   - Y轴: accuracy (蓝线), val_accuracy (橙线)
   - 观察: 两线应该接近，gap过大表示过拟合

2. **平均正确性对比**:
   - X轴: step
   - Y轴: avg_correctness_score, val_avg_correctness
   - 细粒度评分变化

3. **泛化Gap监控**:
   - 自定义指标: `accuracy - val_accuracy`
   - 理想: 趋近于0
   - 警戒: >10%

---

## 🎯 性能分析

### 时间成本

**单次验证评估**:
- 50个样本
- 每个样本 ~3-5秒（生成+执行）
- 总计: ~2.5-4分钟

**每10步验证的影响**:
```
训练500步:
- 验证次数: 50次
- 验证总时间: ~2-3小时
- 训练总时间: ~15-20小时
- 验证占比: 10-15%  ← 可接受
```

### 优化建议

**如果验证太慢**:

1. **减少样本数**:
   ```yaml
   val_samples: 30  # 从50降到30
   ```

2. **降低频率**:
   ```yaml
   eval_every: 20  # 从10改为20
   ```

3. **并行评估**（未来优化）:
   - 当前串行执行50个样本
   - 可改为batch并行（需修改代码）

---

## 🔍 调试与验证

### 1. 验证数据集存在性

```bash
# 检查验证集文件
ls -lh data/val/

# 查看验证集样本
head -n 5 data/val/mixed_dataset.jsonl | jq '.'

# 统计各类型数量
jq -r '.problem_type' data/val/mixed_dataset.jsonl | sort | uniq -c
```

### 2. 手动测试验证功能

```python
import asyncio
from grpo_trainer import GRPOTrainer

async def test_validation():
    trainer = GRPOTrainer(config_path="config/training.yaml")

    # 运行一次验证评估
    val_metrics = await trainer.evaluate_on_val_set(num_samples=10)

    print("验证指标:", val_metrics)

asyncio.run(test_validation())
```

### 3. 检查WandB记录

```python
import wandb

# 在WandB中查询
run = wandb.Api().run("your-entity/your-project/run-id")

# 获取验证准确率历史
val_accuracy_history = run.history(keys=["val_accuracy"])
print(val_accuracy_history)
```

---

## 📊 预期效果

### 理想曲线

**训练初期** (Step 1-20):
```
训练集: 70% → 85%  (快速提升)
验证集: 65% → 80%  (跟随提升)
Gap: 5-7%          (正常学习)
```

**训练中期** (Step 21-100):
```
训练集: 85% → 95%  (持续提升)
验证集: 80% → 92%  (稳定跟随)
Gap: 3-5%          (良好泛化)
```

**训练后期** (Step 101-500):
```
训练集: 95% → 98%  (缓慢提升)
验证集: 92% → 96%  (接近饱和)
Gap: 2-3%          (优秀泛化)
```

### 异常情况

**过拟合信号**:
```
训练集: 98%
验证集: 85%
Gap: 13%  ← ⚠️ 过拟合！
```

**对策**:
1. 提前停止训练（early stopping）
2. 增加正则化（调整reward_weights）
3. 使用更多验证样本
4. 减少few-shot示例数量

**欠拟合信号**:
```
训练集: 75%
验证集: 73%
Gap: 2%   ← 两者都低
```

**对策**:
1. 继续训练更多步
2. 增加few-shot示例
3. 检查operator覆盖是否充分

---

## 🚀 使用方法

### 标准训练（自动验证）

```bash
cd /home/yijia/.claude/11/integrated_aflow_roll

# 使用默认配置（每10步验证）
CUDA_VISIBLE_DEVICES=2 python src/train.py --config config/training.yaml
```

**预期输出**:
- Step 10: 首次验证
- Step 20: 第二次验证
- ...
- Step 500: 最后一次验证（共50次）

### 自定义验证频率

**更频繁验证**（调试阶段）:
```yaml
eval_every: 5
val_samples: 20
```

**较少验证**（生产训练）:
```yaml
eval_every: 25
val_samples: 100
```

### 禁用验证（对比实验）

```yaml
eval_every: 999999  # 实际上永不验证
```

或者临时注释代码:
```python
# if step % eval_every == 0:
#     val_metrics = await self.evaluate_on_val_set(...)
```

---

## 📚 实现细节

### 代码位置

**验证评估方法**:
- 文件: `src/grpo_trainer.py`
- 方法: `evaluate_on_val_set(num_samples: int = 50)`
- 行数: ~110行

**训练循环集成**:
- 文件: `src/grpo_trainer.py`
- 方法: `train()`
- 验证调用: Line ~710

### 与训练的区别

| 维度 | 训练集 | 验证集 |
|------|--------|--------|
| **数据来源** | `split="train"` | `split="val"` |
| **样本数** | 4个/batch | 50个/评估 |
| **梯度更新** | ✅ 执行 | ❌ 不执行 |
| **GRPO归一化** | ✅ 执行 | ❌ 不执行 |
| **Buffer收集** | ✅ 收集 | ❌ 不收集 |
| **目的** | 学习策略 | 评估泛化 |

### 关键设计

1. **不影响训练**: 验证评估不更新模型参数
2. **使用动态提示词**: 与训练保持一致，包括few-shot
3. **独立指标**: val_* 前缀，避免混淆
4. **自动记录**: WandB自动记录，无需手动

---

## 🎉 总结

### 实现亮点

✅ **完全自动化**: 无需手动干预
✅ **实时监控**: WandB可视化
✅ **泛化评估**: 真实性能指标
✅ **可配置**: 频率和样本数可调
✅ **零侵入**: 不影响训练逻辑

### 预期收益

🎯 **及时发现过拟合**: 训练集98% vs 验证集85%
🎯 **指导超参数**: Gap过大时调整配置
🎯 **提前停止**: 验证集不再提升时停止
🎯 **模型选择**: 选择验证集最优的checkpoint
🎯 **真实评估**: 不被训练集准确率误导

### 下一步行动

1. ✅ **立即可用**: 配置已添加，代码已集成
2. 📊 **Step 10**: 观察首次验证结果
3. 📈 **Step 50**: 分析训练/验证gap
4. 🎯 **Step 100+**: 根据gap调整策略
5. 🏆 **训练结束**: 选择val_accuracy最高的checkpoint

---

**实现完成时间**: 2025-11-18
**实现者**: Claude (Sonnet 4.5)
**集成状态**: ✅ 完全集成到主训练流程

**祝训练顺利，泛化能力优秀！** 🚀
